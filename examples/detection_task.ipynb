{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "os.chdir(\"..\")\n",
    "\n",
    "from epilearn.models.SpatialTemporal.STGCN import STGCN\n",
    "\n",
    "from epilearn.models.Spatial.GCN import GCN\n",
    "from epilearn.models.Spatial.SAGE import SAGE\n",
    "from epilearn.models.Spatial.GAT import GAT\n",
    "from epilearn.models.Spatial.GIN import GIN\n",
    "\n",
    "from epilearn.data import UniversalDataset\n",
    "from epilearn.utils import utils, transforms\n",
    "from epilearn.utils import simulation\n",
    "from epilearn.tasks.detection import Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial settings\n",
    "device = torch.device('cpu')\n",
    "torch.manual_seed(7)\n",
    "\n",
    "lookback = 1 # inputs size\n",
    "horizon = 2 # predicts size; also seen as number of classes\n",
    "\n",
    "epochs = 50 # training epochs\n",
    "batch_size = 25 # training batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load toy dataset\n",
    "dataset = UniversalDataset()\n",
    "dataset.load_toy_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize model and task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = Detection(prototype=GCN, dataset=None, lookback=lookback, horizon=horizon, device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation = transforms.Compose({\n",
    "#                                  'features':[transforms.normalize_feat()], \n",
    "#                                  'graph': [transforms.normalize_adj()], \n",
    "#                                  'dynamic_graph': [transforms.normalize_adj()], \n",
    "#                                  'states': []\n",
    "#                                  })\n",
    "transformation = transforms.Compose({\n",
    "                                 'features':[], \n",
    "                                 'graph': [], \n",
    "                                 'dynamic_graph': [], \n",
    "                                 'states': []\n",
    "                                 })\n",
    "dataset.transforms = transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spatial model loaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< Updated upstream
      " 40%|████      | 2/5 [14:29<17:53, 358.00s/it]"
=======
      " 20%|██        | 1/5 [00:21<01:27, 21.97s/it]"
>>>>>>> Stashed changes
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######### epoch:0\n",
<<<<<<< Updated upstream
      "Training loss: 1.3074700832366943\n",
      "Validation loss: 2.0490972995758057\n",
      "######### epoch:1\n",
      "Training loss: 0.6562924385070801\n",
      "Validation loss: 0.7404045462608337\n"
=======
      "Training loss: 1.8975600004196167\n",
      "Validation loss: 2.861781120300293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:47<01:11, 23.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######### epoch:1\n",
      "Training loss: 1.2397278547286987\n",
      "Validation loss: 1.442754864692688\n"
>>>>>>> Stashed changes
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< Updated upstream
      " 80%|████████  | 4/5 [14:29<01:57, 117.83s/it]"
=======
      " 60%|██████    | 3/5 [01:09<00:46, 23.22s/it]"
>>>>>>> Stashed changes
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######### epoch:2\n",
<<<<<<< Updated upstream
      "Training loss: 0.39743882417678833\n",
      "Validation loss: 0.4151507318019867\n",
      "######### epoch:3\n",
      "Training loss: 0.29537877440452576\n",
      "Validation loss: 0.2957361340522766\n"
=======
      "Training loss: 0.857474684715271\n",
      "Validation loss: 1.2778254747390747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [01:32<00:22, 22.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######### epoch:3\n",
      "Training loss: 0.5894216299057007\n",
      "Validation loss: 0.9511571526527405\n"
>>>>>>> Stashed changes
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< Updated upstream
      "100%|██████████| 5/5 [14:29<00:00, 173.96s/it]\n"
=======
      "100%|██████████| 5/5 [01:53<00:00, 22.75s/it]"
>>>>>>> Stashed changes
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######### epoch:4\n",
<<<<<<< Updated upstream
      "Training loss: 0.2295624166727066\n",
      "Validation loss: 0.22758394479751587\n",
      "\n",
      "Final Training loss: 0.2295624166727066\n",
      "Final Validation loss: 0.22758394479751587\n",
      "Best Epoch: 4\n",
      "Best Training loss: 0.2295624166727066\n",
      "Best Validation loss: 0.22758394479751587\n",
      "\n",
      "Predicting Progress...\n"
=======
      "Training loss: 0.5351558327674866\n",
      "Validation loss: 0.6486267447471619\n",
      "\n",
      "Final Training loss: 0.5351558327674866\n",
      "Final Validation loss: 0.6486267447471619\n",
      "Best Epoch: 4\n",
      "Best Training loss: 0.5351558327674866\n",
      "Best Validation loss: 0.6486267447471619\n"
>>>>>>> Stashed changes
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< Updated upstream
      "100%|██████████| 108/108 [00:00<00:00, 959.62it/s]"
=======
      "\n"
>>>>>>> Stashed changes
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting Progress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 108/108 [00:38<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ACC: 2.194444417953491\n"
     ]
    }
   ],
   "source": [
    "config = None\n",
    "result = task.train_model(dataset=dataset, config=config, loss='ce', epochs=5) # instead of config, we can also dircetly input some parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on Simulated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation Process\n",
    "from epilearn.models.SpatialTemporal.NetworkSIR import NetSIR\n",
    "\n",
    "# generate 10 samples\n",
    "num_nodes = 25\n",
    "# generate random static graph: 25 nodes\n",
    "initial_graph = simulation.get_random_graph(num_nodes=num_nodes, connect_prob=0.15)\n",
    "initial_states = torch.zeros(num_nodes,3) # [S,I,R]\n",
    "initial_states[:, 0] = 1\n",
    "\n",
    "graph = initial_graph\n",
    "x = []\n",
    "y = []\n",
    "for i in range(100): \n",
    "    # set infected individual\n",
    "    idx = torch.randint(0,num_nodes, (1,))\n",
    "    initial_states[idx.item(), 0] = 0\n",
    "    initial_states[idx.item(), 1] = 1\n",
    "\n",
    "    model = NetSIR(num_nodes=initial_graph.shape[0], horizon=100, infection_rate=0.01, recovery_rate=0.0384) # infection_rate, recover_rate, fixed_population\n",
    "    preds = model(initial_states, initial_graph, steps = None)\n",
    "    x.append(torch.nn.functional.one_hot(preds[-1].argmax(1)))\n",
    "    y.append(initial_states.argmax(1))\n",
    "x = torch.stack(x)\n",
    "y = torch.stack(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = UniversalDataset(x=x,y=y,graph=initial_graph)\n",
    "dataset.transforms = transformation\n",
    "task = Detection(prototype=GCN, dataset=dataset, lookback=lookback, horizon=horizon, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
<<<<<<< Updated upstream
   "outputs": [],
=======
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spatial model loaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:02<00:08,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######### epoch:0\n",
      "Training loss: 0.6597769856452942\n",
      "Validation loss: 0.5772261023521423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:05<00:07,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######### epoch:1\n",
      "Training loss: 0.6493467688560486\n",
      "Validation loss: 0.5620183944702148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:10<00:07,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######### epoch:2\n",
      "Training loss: 0.644253671169281\n",
      "Validation loss: 0.5452414751052856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:14<00:04,  4.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######### epoch:3\n",
      "Training loss: 0.6366496682167053\n",
      "Validation loss: 0.5283515453338623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:19<00:00,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######### epoch:4\n",
      "Training loss: 0.6305637955665588\n",
      "Validation loss: 0.5115376114845276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Training loss: 0.6305637955665588\n",
      "Final Validation loss: 0.5115376114845276\n",
      "Best Epoch: 4\n",
      "Best Training loss: 0.6305637955665588\n",
      "Best Validation loss: 0.5115376114845276\n",
      "\n",
      "Predicting Progress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:07<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ACC: 24.0\n"
     ]
    }
   ],
>>>>>>> Stashed changes
   "source": [
    "result = task.train_model(dataset=dataset, loss='ce', epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dreamy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
