{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T07:45:41.170717900Z",
     "start_time": "2024-04-26T07:45:41.100208300Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "os.chdir(\"..\")\n",
    "\n",
    "from epilearn.models.SpatialTemporal.STGCN import STGCN\n",
    "from epilearn.models.SpatialTemporal.ATMGNN import MPNN_LSTM, ATMGNN\n",
    "from epilearn.models.SpatialTemporal.STAN import STAN\n",
    "\n",
    "\n",
    "from epilearn.data import UniversalDataset\n",
    "from epilearn.utils import utils, metrics\n",
    "from epilearn.utils import transforms\n",
    "\n",
    "# initial settings\n",
    "device = torch.device('cpu')\n",
    "torch.manual_seed(7)\n",
    "\n",
    "lookback = 12 # inputs size\n",
    "horizon = 3 # predicts size\n",
    "\n",
    "# permutation is True when using STGCN\n",
    "permute = False\n",
    "\n",
    "epochs = 50 # training epochs\n",
    "batch_size = 50 # training batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load toy dataset\n",
    "dataset = UniversalDataset()\n",
    "dataset.load_toy_dataset()\n",
    "\n",
    "# initialize transforms\n",
    "transformation = transforms.Compose({\n",
    "                                    'features': [\n",
    "                                                    transforms.normalize_feat(),\n",
    "\n",
    "                                                ],\n",
    "                                    'graph': [\n",
    "                                                transforms.normalize_adj(),\n",
    "                                                    \n",
    "                                            ],\n",
    "                                    'dynamic_graph': [\n",
    "                                                        transforms.normalize_adj(),\n",
    "                                                    \n",
    "                                                    ],\n",
    "                                    'states': []\n",
    "                                    })\n",
    "\n",
    "\n",
    "# preprocessing dataset\n",
    "dataset.transforms = transformation\n",
    "\n",
    "features, adj_norm, adj_dynamic_norm, states = dataset.get_transformed()\n",
    "mean, std = dataset.transforms.feat_mean, dataset.transforms.feat_std\n",
    "\n",
    "features = features.to(device)\n",
    "adj_norm = adj_norm.to(device)\n",
    "adj_dynamic_norm = adj_dynamic_norm.to(device)\n",
    "\n",
    "# split data\n",
    "train_rate = 0.6 \n",
    "val_rate = 0.2\n",
    "\n",
    "target_feat_idx = None\n",
    "target_idx = None\n",
    "\n",
    "split_line1 = int(features.shape[0] * train_rate)\n",
    "split_line2 = int(features.shape[0] * (train_rate + val_rate))\n",
    "\n",
    "train_original_data = features[:split_line1, :, :]\n",
    "val_original_data = features[split_line1:split_line2, :, :]\n",
    "test_original_data = features[split_line2:, :, :]\n",
    "\n",
    "train_original_states = dataset.states[:split_line1, :, :]\n",
    "val_original_states = dataset.states[split_line1:split_line2, :, :]\n",
    "test_original_states = dataset.states[split_line2:, :, :]\n",
    "\n",
    "train_input, train_target, train_states, train_adj = dataset.generate_dataset(X = train_original_data, Y = train_original_data[..., 0], states = train_original_states, dynamic_adj = adj_dynamic_norm, lookback_window_size = lookback, horizon_size = horizon, permute = permute, feat_idx = target_feat_idx, target_idx = target_idx)\n",
    "val_input, val_target, val_states, val_adj = dataset.generate_dataset(X = val_original_data, Y = val_original_data[..., 0], states = val_original_states, dynamic_adj = adj_dynamic_norm, lookback_window_size = lookback, horizon_size = horizon, permute = permute, feat_idx = target_feat_idx, target_idx = target_idx)\n",
    "test_input, test_target, test_states, test_adj = dataset.generate_dataset(X = test_original_data, Y = test_original_data[..., 0], states = test_original_states, dynamic_adj = adj_dynamic_norm, lookback_window_size = lookback, horizon_size = horizon, permute = permute, feat_idx = target_feat_idx, target_idx = target_idx)\n",
    "\n",
    "\n",
    "# prepare model\n",
    "\n",
    "# model = STGCN(\n",
    "#             num_nodes=adj_norm.shape[0],\n",
    "#             num_features=train_input.shape[3],\n",
    "#             num_timesteps_input=lookback,\n",
    "#             num_timesteps_output=horizon\n",
    "#             ).to(device=device)\n",
    "\n",
    "model = MPNN_LSTM(\n",
    "                num_nodes=adj_norm.shape[0],\n",
    "                num_features=train_input.shape[3],\n",
    "                num_timesteps_input=lookback,\n",
    "                num_timesteps_output=horizon,\n",
    "                nhid=4\n",
    "                ).to(device=device)\n",
    "\n",
    "# model = ATMGNN(\n",
    "#                 num_nodes=adj_norm.shape[0],\n",
    "#                 num_features=train_input.shape[3],\n",
    "#                 num_timesteps_input=lookback,\n",
    "#                 num_timesteps_output=horizon,\n",
    "#                 nhid=4\n",
    "#                 ).to(device=device)\n",
    "\n",
    "# model = STAN(\n",
    "#             num_nodes=adj_norm.shape[0],\n",
    "#             num_features=train_input.shape[3],\n",
    "#             num_timesteps_input=lookback,\n",
    "#             num_timesteps_output=horizon\n",
    "#             ).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:00<00:18,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######### epoch:0\n",
      "Training loss: 0.1916363388299942\n",
      "Validation loss: 0.3787970542907715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:18<00:00,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Final Training loss: 0.17109046876430511\n",
      "Final Validation loss: 0.3942277729511261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "model.fit(\n",
    "        train_input=train_input, \n",
    "        train_target=train_target,\n",
    "        train_states = train_states, \n",
    "        train_graph=adj_norm,  # for dynamic graph, use val_adj\n",
    "        val_input=val_input, \n",
    "        val_target=val_target, \n",
    "        val_states=val_states,\n",
    "        val_graph=adj_norm,  # for dynamic graph, use val_adj\n",
    "        loss='mse',\n",
    "        verbose=True,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 196.19422912597656\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "out = model.predict(feature=test_input, graph=adj_norm)\n",
    "preds = out.detach().cpu()*std[0]+mean[0]\n",
    "targets = test_target.detach().cpu()*std[0]+mean[0]\n",
    "# MAE\n",
    "mae = metrics.get_MAE(preds, targets)\n",
    "print(f\"MAE: {mae.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # visualization\n",
    "# out = model.predict(feature=train_input, graph=adj_norm).detach().cpu()\n",
    "\n",
    "# sample = 28\n",
    "\n",
    "# plt.figure(figsize=(15 ,5))\n",
    "# for i in range(1, 4):\n",
    "#     sample_input=train_input[sample, i, :, 0]\n",
    "#     sample_output=out[sample, i, :]\n",
    "#     sample_target=train_target[sample, i, :]\n",
    "\n",
    "#     vis_data = torch.cat([sample_input, sample_target]).numpy()\n",
    "    \n",
    "#     plt.subplot(1, 3, i)\n",
    "#     rng = list(range(lookback+horizon))\n",
    "#     plt.plot(rng, vis_data, label=\"ground truth\")\n",
    "#     plt.plot(rng[lookback:lookback+horizon], sample_output.numpy(), label=\"prediction\")\n",
    "#     plt.legend()\n",
    "\n",
    "\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dreamy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
