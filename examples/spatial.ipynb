{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "os.chdir(\"..\")\n",
    "#os.sys.path.append(\"./Dreamy\")\n",
    "from epilearn.models.SpatialTemporal.STGCN import STGCN\n",
    "from epilearn.models.Spatial.GCN import GCN\n",
    "from epilearn.models.Spatial.GAT import GAT\n",
    "from epilearn.models.Spatial.SAGE import SAGE\n",
    "from epilearn.models.Spatial.DCRNN import DCRNN\n",
    "from epilearn.models.Spatial.GIN import GIN\n",
    "from epilearn.models.SpatialTemporal.GraphWaveNet import gwnet\n",
    "from epilearn.data import UniversalDataset, SpatialDataset\n",
    "from epilearn.utils import utils, metrics\n",
    "\n",
    "import torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# initial settings\n",
    "#device = torch.device('cpu')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "torch.manual_seed(7)\n",
    "\n",
    "lookback = 13 # inputs size\n",
    "horizon = 1 # predicts size\n",
    "\n",
    "epochs = 50 # training epochs\n",
    "batch_size = 2 # training batch size\n",
    "\n",
    "permute = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load toy dataset\n",
    "dataset = UniversalDataset()\n",
    "dataset.load_toy_dataset()\n",
    "\n",
    "# preprocessing\n",
    "features, mean, std = utils.normalize(dataset.x)\n",
    "adj_norm = utils.normalize_adj(dataset.graph)\n",
    "adj_dynamic_norm = utils.normalize_adj(dataset.dynamic_graph)\n",
    "\n",
    "features = features.to(device)\n",
    "adj_norm = adj_norm.to(device)\n",
    "adj_dynamic_norm = adj_dynamic_norm.to(device)\n",
    "\n",
    "# prepare datasets\n",
    "train_rate = 0.6 \n",
    "val_rate = 0.2\n",
    "\n",
    "target_feat_idx = None\n",
    "target_idx = None\n",
    "\n",
    "split_line1 = int(features.shape[0] * train_rate)\n",
    "split_line2 = int(features.shape[0] * (train_rate + val_rate))\n",
    "\n",
    "train_original_data = features[:split_line1, :, :]\n",
    "val_original_data = features[split_line1:split_line2, :, :]\n",
    "test_original_data = features[split_line2:, :, :]\n",
    "\n",
    "train_original_states = dataset.states[:split_line1, :, :]\n",
    "val_original_states = dataset.states[split_line1:split_line2, :, :]\n",
    "test_original_states = dataset.states[split_line2:, :, :]\n",
    "\n",
    "train_input, train_target, train_states, train_adj = dataset.generate_dataset(X = train_original_data, Y = train_original_data[..., 0], states = train_original_states, dynamic_adj = adj_dynamic_norm, lookback_window_size = lookback, horizon_size = horizon, permute = permute, feat_idx = target_feat_idx, target_idx = target_idx)\n",
    "val_input, val_target, val_states, val_adj = dataset.generate_dataset(X = val_original_data, Y = val_original_data[..., 0], states = val_original_states, dynamic_adj = adj_dynamic_norm, lookback_window_size = lookback, horizon_size = horizon, permute = permute, feat_idx = target_feat_idx, target_idx = target_idx)\n",
    "test_input, test_target, test_states, test_adj = dataset.generate_dataset(X = test_original_data, Y = test_original_data[..., 0], states = test_original_states, dynamic_adj = adj_dynamic_norm, lookback_window_size = lookback, horizon_size = horizon, permute = permute, feat_idx = target_feat_idx, target_idx = target_idx)\n",
    "\n",
    "rows, cols = torch.where(adj_norm != 0)\n",
    "weights = adj_norm[rows, cols]\n",
    "\n",
    "edge_index = torch.stack([rows.long(), cols.long()], dim=0).to(device)\n",
    "edge_weight = weights.clone().detach().to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([310, 47, 13, 4])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = SpatialDataset(x=train_input[..., 0,:], y=train_target, adj_m=adj_norm)\n",
    "# val_dataset = SpatialDataset(x=val_input[..., 0,:], y=val_target, edge_index=edge_index, edge_attr=edge_weight)\n",
    "train_dataset = UniversalDataset(x=train_input[..., 0,:], y=train_target, graph=adj_norm, edge_index=edge_index, edge_weight=edge_weight)\n",
    "val_dataset = UniversalDataset(x=val_input[..., 0,:], y=val_target, graph=adj_norm, edge_index=edge_index, edge_weight=edge_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN(input_dim=train_input.shape[3],\n",
    "        hidden_dim=16,\n",
    "        output_dim=horizon,\n",
    "        nlayers=2, with_bn=True,\n",
    "        dropout=0.3, device=device)\n",
    "\n",
    "'''model = GAT(input_dim=train_input.shape[2]*train_input.shape[3],\n",
    "        hidden_dim=16,\n",
    "        output_dim=horizon,\n",
    "        nlayers=2, with_bn=True, nheads=[2,4], concat=True,\n",
    "        dropout=0.3, device=device)'''\n",
    "\n",
    "'''model = SAGE(input_dim=train_input.shape[2]*train_input.shape[3],\n",
    "        hidden_dim=16,\n",
    "        output_dim=horizon,\n",
    "        nlayers=1, with_bn=True, aggr=torch_geometric.nn.GRUAggregation,\n",
    "        dropout=0.3, device=device)'''\n",
    "        \n",
    "\n",
    "'''model = DCRNN(input_dim=train_input.shape[3],\n",
    "              seq_len=lookback,\n",
    "              output_dim=1,\n",
    "              horizon=horizon,\n",
    "              max_diffusion_step=2, \n",
    "              filter_type=\"laplacian\",\n",
    "              num_rnn_layers=1, \n",
    "              rnn_units=1,\n",
    "              nonlinearity=\"tanh\",\n",
    "              dropout=0.5,\n",
    "              device=device)'''\n",
    "\n",
    "'''model = GIN(input_dim=train_input.shape[2]*train_input.shape[3],\n",
    "        hidden_dim=16,\n",
    "        output_dim=horizon,\n",
    "        nlayers=2, \n",
    "        dropout=0.3, device=device)'''\n",
    "\n",
    "\n",
    "# train_input = torch.permute(train_input, (0, 2, 1, 3))\n",
    "# train_input = train_input.transpose(1, 3)\n",
    "\n",
    "# val_input = torch.permute(val_input, (0, 2, 1, 3))\n",
    "# val_input = val_input.transpose(1, 3)\n",
    "\n",
    "# supports = [i.clone().detach().to(device).unsqueeze(0) for i in adj_norm]\n",
    "# model = gwnet(device, \n",
    "#               num_nodes=47, dropout=0.3, \n",
    "#               supports=supports, gcn_bool=True, \n",
    "#               addaptadj=True, aptinit=None, \n",
    "#               in_dim=train_input.shape[1], out_dim=horizon, \n",
    "#               residual_channels=32, dilation_channels=32, \n",
    "#               skip_channels=32 * 8, end_channels=32 * 16)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([310, 47, 4])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:00<00:19,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######### epoch:0\n",
      "Training loss: 0.1334879994392395\n",
      "Validation loss: 0.14645631611347198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [00:00<00:19,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######### epoch:1\n",
      "Training loss: 0.10505305975675583\n",
      "Validation loss: 0.15544074773788452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [00:01<00:16,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######### epoch:2\n",
      "Training loss: 0.09900037199258804\n",
      "Validation loss: 0.15536688268184662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [00:01<00:15,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######### epoch:3\n",
      "Training loss: 0.09785710275173187\n",
      "Validation loss: 0.15625570714473724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [00:01<00:15,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######### epoch:4\n",
      "Training loss: 0.09465417265892029\n",
      "Validation loss: 0.1585649847984314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [00:02<00:14,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######### epoch:5\n",
      "Training loss: 0.09155978262424469\n",
      "Validation loss: 0.16654406487941742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [00:02<00:17,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######### epoch:6\n",
      "Training loss: 0.08829563111066818\n",
      "Validation loss: 0.1660740226507187\n",
      "Early stop at Epoch 6!\n",
      "\n",
      "Final Training loss: 0.08829563111066818\n",
      "Final Validation loss: 0.1660740226507187\n",
      "Best Epoch: 0\n",
      "Best Training loss: 0.1334879994392395\n",
      "Best Validation loss: 0.14645631611347198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#train_input = torch.reshape(train_input, (train_input.shape[0], train_input.shape[1], -1))\n",
    "\n",
    "\n",
    "# model.fit(\n",
    "#         train_input=train_input, \n",
    "#         train_target=train_target, \n",
    "#         graph=adj_norm, \n",
    "#         val_input=val_input, \n",
    "#         val_target=val_target, \n",
    "#         verbose=True,\n",
    "#         batch_size=batch_size,\n",
    "#         epochs=epochs)\n",
    "\n",
    "model.fit(\n",
    "        train_dataset = train_dataset, \n",
    "        val_dataset = val_dataset, \n",
    "        verbose = True, \n",
    "        batch_size = batch_size,\n",
    "        lr=1e-3,\n",
    "        shuffle=False,\n",
    "        patience=5,\n",
    "        epochs = epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[1, 47, 4], edge_index=[2, 2189], edge_attr=[2189], y=[1, 47, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting Progress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:00<00:00, 1057.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([95, 47, 1])\n",
      "MAE: 221.47412109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "output_dim=[47, horizon]\n",
    "test_dataset = UniversalDataset(x=test_input[..., 0,:], edge_index=edge_index)\n",
    "out = model.predict(dataset=test_dataset, batch_size=batch_size, device=device, output_dim=output_dim)\n",
    "print(out.shape)\n",
    "\n",
    "preds = out.detach().cpu() * std[0] + mean[0]\n",
    "targets = test_target.detach().cpu() * std[0] + mean[0]\n",
    "# MAE\n",
    "mae = metrics.get_MAE(preds, targets)\n",
    "print(f\"MAE: {mae.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dreamy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
